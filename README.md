# Feelings Analysis - Classification multi-aspects de sentiments

Projet d'analyse de sentiments multi-aspects pour des avis de restaurants en fran√ßais. Le syst√®me classifie automatiquement 4 aspects (**Prix**, **Cuisine**, **Service**, **Ambiance**) selon 4 labels : **Positive**, **N√©gative**, **Neutre**, **NE** (Non Exprim√©).

## Vue d'ensemble

Ce projet impl√©mente deux approches de classification :

1. **LLM** : Classification zero-shot avec des mod√®les de langage (via Ollama)
2. **PLMFT** : Fine-tuning de mod√®les pr√©-entra√Æn√©s (CamemBERT-Large) avec PyTorch Lightning

**Statut actuel** : Le syst√®me PLMFT est pleinement op√©rationnel avec des optimisations avanc√©es pour atteindre ~85% d'accuracy.

---

## Architecture du Projet

```
FeelingsAnalysis/
‚îú‚îÄ‚îÄ data/                           # Donn√©es d'entra√Ænement et test
‚îÇ   ‚îú‚îÄ‚îÄ ftdataset_train.tsv        # Ensemble d'entra√Ænement
‚îÇ   ‚îú‚îÄ‚îÄ ftdataset_val.tsv          # Ensemble de validation
‚îÇ   ‚îî‚îÄ‚îÄ ftdataset_test.tsv         # Ensemble de test
‚îú‚îÄ‚îÄ src/                            # Code source
‚îÇ   ‚îú‚îÄ‚îÄ config.py                  # Configuration et hyperparam√®tres
‚îÇ   ‚îú‚îÄ‚îÄ classifier_wrapper.py      # Wrapper unifi√© pour LLM/PLMFT
‚îÇ   ‚îú‚îÄ‚îÄ llm_classifier.py          # Classificateur LLM zero-shot
‚îÇ   ‚îú‚îÄ‚îÄ plm_classifier.py          # Classificateur PLMFT (CamemBERT)
‚îÇ   ‚îú‚îÄ‚îÄ runproject.py              # Point d'entr√©e principal
‚îÇ   ‚îî‚îÄ‚îÄ lightning_logs/            # Logs d'exp√©riences PyTorch Lightning
‚îÇ       ‚îú‚îÄ‚îÄ version_0/
‚îÇ       ‚îú‚îÄ‚îÄ version_1/
‚îÇ       ‚îî‚îÄ‚îÄ version_2/             # Meilleure exp√©rience actuelle
‚îú‚îÄ‚îÄ requirements.txt               # D√©pendances Python
‚îú‚îÄ‚îÄ install.sh                     # Script d'installation
‚îî‚îÄ‚îÄ README.md                      # Ce fichier
```

---

## Dataset

**Format** : Fichiers TSV (Tab-Separated Values)

| Colonne    | Description                                      |
|------------|--------------------------------------------------|
| `Avis`     | Texte de l'avis client                          |
| `Prix`     | Sentiment sur le prix                           |
| `Cuisine`  | Sentiment sur la qualit√© de la cuisine          |
| `Service`  | Sentiment sur le service                        |
| `Ambiance` | Sentiment sur l'ambiance                        |

**Labels possibles** : `Positive`, `N√©gative`, `Neutre`, `NE` (Non Exprim√©)

**Caract√©ristiques** :
- **Classification multi-sortie** : 4 t√¢ches de classification ind√©pendantes
- **4 classes** par aspect
- D√©s√©quilibre de classes possible (notamment `NE`)

---

## Installation

### Pr√©requis
- Python 3.8+
- CUDA 11.8+ (pour GPU)
- 16GB+ RAM recommand√©

### Installation rapide

```bash
pip install -r requirements.txt
```

### D√©pendances principales
- `torch` : Deep Learning
- `transformers` : Mod√®les pr√©-entra√Æn√©s (CamemBERT)
- `lightning` : Framework d'entra√Ænement
- `pandas` : Manipulation de donn√©es
- `ollama` : Interface LLM (mode LLM uniquement)

---

## Utilisation

### Configuration de la m√©thode

Dans [`classifier_wrapper.py`](file:///home/decoopmn/FeelingsAnalysis/src/classifier_wrapper.py#L12), modifier :

```python
METHOD: str = 'PLMFT'  # ou 'LLM'
```

### Lancer l'entra√Ænement et l'√©valuation

```bash
cd src/
python runproject.py --device=0 --n_runs=5
```

**Arguments disponibles** :
- `--device=0` : Utiliser GPU 0 (-1 pour CPU)
- `--n_runs=5` : Nombre d'ex√©cutions (moyenne finale)
- `--n_train=1000` : Limiter l'entra√Ænement (d√©faut: -1 = tout)
- `--n_test=500` : Limiter les tests (d√©faut: -1 = tout)
- `--batch_size=32` : Taille de batch
- `--learning_rate=2e-5` : Taux d'apprentissage
- `--max_epochs=20` : Nombre d'√©poques max

---

## Configuration et hyperparam√®tres

Le fichier [`config.py`](file:///home/decoopmn/FeelingsAnalysis/src/config.py) centralise tous les hyperparam√®tres.

### Hyperparam√®tres actuels (optimis√©s pour version_2)

```python
batch_size: int = 32                    # Taille de batch
accumulate_grad_batches: int = 4        # Gradient accumulation (batch effectif = 128)
learning_rate: float = 2e-5             # LR t√™tes de classification
backbone_lr: float = 1e-5               # LR backbone CamemBERT (discriminative LR)
max_epochs: int = 20                    # Nombre d'√©poques max
max_length: int = 256                   # Longueur max des s√©quences
weight_decay: float = 0.01              # R√©gularisation L2
warmup_steps: int = 1000                # Steps de warmup (linear)
scheduler: str = "linear"               # Scheduler LR (linear ou cosine)
early_stopping_patience: int = 3        # Early stopping sur val_loss
```

### Optimisations impl√©ment√©es

**Gradient checkpointing** : R√©duit l'utilisation m√©moire GPU  
**Mixed precision training** (FP16) : Acc√©l√©ration ~2-3x  
**Discriminative learning rates** : LR diff√©rent backbone/t√™tes  
**Label smoothing** (0.1) : R√©duit l'overfitting  
**Gradient accumulation** : Simule de plus gros batchs  
**Warmup + Linear/cosine scheduler** : Stabilise l'entra√Ænement  
**Early stopping** : Arr√™t automatique si pas d'am√©lioration  
**DataLoader optimis√©** : `num_workers=8`, `pin_memory=True`, `persistent_workers=True`

---

## Architecture du mod√®le

### Mod√®le PLMFT ([`plm_classifier.py`](file:///home/decoopmn/FeelingsAnalysis/src/plm_classifier.py))

```
Input Text
    ‚Üì
[Tokenizer CamemBERT]
    ‚Üì
[CamemBERT-Large Backbone]  ‚Üê Gradient Checkpointing activ√©
    ‚Üì
[CLS Token Pooling]
    ‚Üì
    ‚îú‚îÄ‚Üí [Linear Layer] ‚Üí Prix (4 classes)
    ‚îú‚îÄ‚Üí [Linear Layer] ‚Üí Cuisine (4 classes)
    ‚îú‚îÄ‚Üí [Linear Layer] ‚Üí Service (4 classes)
    ‚îî‚îÄ‚Üí [Linear Layer] ‚Üí Ambiance (4 classes)
```

**Caract√©ristiques** :
- **Backbone** : `camembert/camembert-large` (110M param√®tres)
- **4 t√™tes de classification** ind√©pendantes (une par aspect)
- **Loss** : CrossEntropyLoss avec label smoothing (0.1)
- **Optimizer** : AdamW avec discriminative learning rates
- **Scheduler** : Linear warmup + linear/cosine decay

### Classe `PLMClassifier`

**M√©thodes principales** :
- `__init__(cfg)` : Initialisation du mod√®le et tokenizer
- `forward(input_ids, attention_mask)` : Passage avant
- `training_step(batch, batch_idx)` : Step d'entra√Ænement
- `validation_step(batch, batch_idx)` : Step de validation
- `configure_optimizers()` : Configuration optimizer + scheduler
- `predict(text)` : Pr√©diction sur un texte unique

---

## R√©sultats et exp√©riences

Les logs d'entra√Ænement sont stock√©s dans `src/lightning_logs/version_X/`.

### Meilleures performances (version_2)

| M√©trique                        | Valeur                                       |
| ------------------------------- | -------------------------------------------- |
| **Val Loss**                    | **1.836**                                    |
| **Val Acc (moyenne 4 classes)** | **0.8599**                                   |
| **Val Acc Ambiance**            | **0.823**                                    |
| **Val Acc Cuisine**             | **0.872**                                    |
| **Val Acc Prix**                | **0.867**                                    |
| **Val Acc Service**             | **0.878**                                    |


### Historique des exp√©riences

Le dossier `lightning_logs/` contient les versions d'exp√©riences avec diff√©rents hyperparam√®tres. Consultez les fichiers `metrics.csv` pour comparer les performances.

---

## üîß Modules principaux

### [`runproject.py`](file:///home/decoopmn/FeelingsAnalysis/src/runproject.py)
Script principal d'orchestration :
- Charge les donn√©es TSV
- Initialise le ClassifierWrapper
- Lance l'entra√Ænement (si PLMFT)
- √âvalue sur le test set
- Calcule les m√©triques par aspect et macro-accuracy

### [`classifier_wrapper.py`](file:///home/decoopmn/FeelingsAnalysis/src/classifier_wrapper.py)
Wrapper unifi√© pour g√©rer LLM et PLMFT :
- `train(train_data, val_data, device)` : Entra√Ænement (PLMFT uniquement)
- `predict(texts, device)` : Pr√©diction batch

### [`plm_classifier.py`](file:///home/decoopmn/FeelingsAnalysis/src/plm_classifier.py)
Impl√©mentation PyTorch Lightning du mod√®le multi-aspects :
- Classe `AspectDataset` : Dataset PyTorch pour multi-aspects
- Classe `PLMClassifier` : LightningModule avec CamemBERT

### [`llm_classifier.py`](file:///home/decoopmn/FeelingsAnalysis/src/llm_classifier.py)
Classificateur zero-shot via LLM (Ollama) :
- G√©n√©ration de prompts structur√©s
- Parsing des r√©ponses JSON
- Fallback en cas d'erreur

---

## Objectifs et am√©liorations

### R√©alis√©
- [x] Fine-tuning CamemBERT-Large multi-aspects
- [x] Optimisations GPU (gradient checkpointing, mixed precision)
- [x] Discriminative learning rates
- [x] Early stopping et schedulers avanc√©s
- [x] Architecture multi-t√™tes pour 4 aspects
- [x] √âvaluation par aspect + macro-accuracy

### En cours
- [ ] Atteindre 93%+ d'accuracy
- [ ] Optimisation des hyperparam√®tres (grid search)
- [ ] Ensembling de mod√®les
- [ ] Data augmentation

### Futures am√©liorations
- [ ] Int√©gration de mod√®les plus r√©cents (DeBERTa, RoBERTa-large)
- [ ] Architecture avec attention crois√©e entre aspects
- [ ] Distillation de mod√®le pour d√©ploiement
- [ ] Interface web pour d√©mo

---

## M√©triques d'√©valuation

Le syst√®me calcule :
- **Accuracy par aspect** : Prix, Cuisine, Service, Ambiance
- **Macro-accuracy** : Moyenne des 4 aspects
- **Validation loss** : Loss moyenne sur tous les aspects

**Exemple de sortie** :
```
Prix: 87.23%
Cuisine: 89.45%
Service: 85.12%
Ambiance: 83.67%
Macro Accuracy: 86.37%
```

---

## Contributing

Pour am√©liorer le projet :
1. Analyser les m√©triques dans `lightning_logs/`
2. Ajuster les hyperparam√®tres dans `config.py`
3. Lancer de nouvelles exp√©riences
4. Documenter les r√©sultats

---

**Note** : Ce projet a √©t√© optimis√© √† travers 24+ exp√©riences pour maximiser la performance sur la classification multi-aspects de sentiments en fran√ßais.